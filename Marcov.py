# -*- coding: utf-8 -*-
"""CPU_perc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W7p0Ue1X8B9U1saEg7YzyYmxR-YV7Fgk
"""

import numpy as np
import pandas as pd
from datetime import datetime

from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential

from google.colab import drive
drive.mount('/content/drive')

"""# Data preprocessing"""

data = pd.read_csv('/content/drive/My Drive/Book1.csv')
# load data from google drive

"""Extract timestamps"""

# extract timestamps and convert them (float) to string (to use it in strptime)
timestamps = data['timestamp'].astype(str)
# print(len(timestamps))
print(len(timestamps))
#function to validate the timestamps if there are in %m/%d/%Y %H:%M format
def validate_timestamp(timestamp_str):
    try:
        datetime.strptime(timestamp_str, "%m/%d/%Y %H:%M")
        return True
    except ValueError:
        return False

# to split the time part and add it to times list
nan_indx_time=[]
times=[]
for i, timestamp in enumerate(timestamps):
  if validate_timestamp(timestamp) and i not in nan_indx_use:
      timestamp_components = timestamp.split(" ")
      times.append(timestamp_components[1])
  else:
    nan_indx_time.append(i)


print(nan_indx_time)
print(times)
print(len(times))

# #convert stringtimes to time type and validate them
ttimes = [datetime.strptime(time, '%H:%M').time() for time in times]
print(ttimes)

# Convert time values to numerical features
def convert_time_to_features(time):
    hour = time.hour
    minute = time.minute
    # return [hour, minute]
    return hour

time_features = [convert_time_to_features(time) for time in ttimes]
print(time_features)

cpu_usage = data['cpu_usage'].astype(str)
nan_indx_use=[]
cpu_usage_perc = []
for i, use in enumerate(cpu_usage):
  if len(use) != 3 and i not in nan_indx_time:
    cpu_usage_perc.append(use)
  if len(use) == 3:
    nan_indx_use.append(i)

fl_cpu_usage_perc = [float(x) for x in cpu_usage_perc]

print(len(cpu_usage_perc))

# X = np.array(time_features).reshape(-1, 2)
# # -1 showed the number of rows is based on the data, and 2 is the number of columns(hour and minute)
# # print(X)
# Y = np.array(cpu_usage_perc)
# # print(Y)

import matplotlib.pyplot as plt

# Calculate the average CPU usage for each hour
average_usage_dict = {}
for hour, usage in zip(time_features, fl_cpu_usage_perc):
    if hour in average_usage_dict:
        average_usage_dict[hour].append(usage)
    else:
        average_usage_dict[hour] = [usage]

average_usage_list = []
for hour, usage_list in average_usage_dict.items():
    average_usage = sum(usage_list) / len(usage_list)
    average_usage_list.append((hour, average_usage))

# Extract hours and average usage from the list of tuples
hours = [hour for hour, usage in average_usage_list]
average_usage = [usage for hour, usage in average_usage_list]

x_axis = hours
y_axis = average_usage
plt.bar(x_axis, y_axis, width=1)
plt.xlabel("Hours")
plt.ylabel("CPU_Use")
plt.show()

"""Marcov"""

states_dict = {"idle":[], "low":[], "high":[]}
for use in fl_cpu_usage_perc:
  if use < 30:
    states_dict["idle"].append(use)
  elif 30 <= use < 70 :
    states_dict["low"].append(use)
  else:
    states_dict["high"].append(use)

print(states_dict)
print(fl_cpu_usage_perc)
print(time_features)

states_dict = {"idle":{"idle":[0], "low":[0], "high":[0]}, "low":{"idle":[0], "low":[0], "high":[0]}, "high":{"idle":[0], "low":[0], "high":[0]}}
converted_to_states = []
idle_count, low_count, high_count = 0, 0, 0

for i in fl_cpu_usage_perc:
  if i < 30 :
    converted_to_states.append("idle")
  elif i <= 70 :
    converted_to_states.append("low")
  else:
    converted_to_states.append("high")

print(converted_to_states)
print(len(converted_to_states))



for i in range(len(fl_cpu_usage_perc) - 1):
    current_usage = fl_cpu_usage_perc[i]
    next_usage = fl_cpu_usage_perc[i + 1]

    if current_usage < 30:
        usage_category = "idle"
        idle_count += 1

    elif 30 <= current_usage <= 70:
        usage_category = "low"
        low_count += 1

    else:
        usage_category = "high"
        high_count += 1

    if next_usage < 30:
        states_dict[usage_category]["idle"][0] += 1
    elif 30 <= next_usage <= 70:
        states_dict[usage_category]["low"][0] += 1
    else:
        states_dict[usage_category]["high"][0] += 1

def get_total_state_count(state):
    if state == "idle":
        return idle_count
    elif state == "low":
        return low_count
    else:
        return high_count

for state in states_dict:
  for next_state in states_dict[state]:
      states_dict[state][next_state].append(states_dict[state][next_state][0] / get_total_state_count(state))



print(states_dict)

print(len(fl_cpu_usage_perc))

import random

def predict_future_states(current_state, states_dict):
    next_states =[]
    total_weight = 0
    for key,value in states_dict[current_state].items():
        total_weight += value[1]
        next_states.append([value[1],key])

    random_number = random.random()
    next_states.sort(key = lambda x : x[0])
    if random_number <= (next_states[0][0]) / total_weight:
        return next_states[0]
    elif random_number <= ((next_states[1][0]) / total_weight):
        return next_states[1]
    else:
        return next_states[2]

#dependent to previous state
def fpredicted_states_dep():
  predicted_states_dep =[]
  for i in range(len(fl_cpu_usage_perc)):
    if i == 0:
      current_state = converted_to_states[0]
    else:
        current_state = predicted_state[1]
    predicted_state = predict_future_states(current_state,states_dict)
    predicted_states_dep.append(predicted_state[1])
  k = 0
  for i in range(len(converted_to_states)):
    if predicted_states_dep[i] == converted_to_states[i] :
      k += 1
  approximation_error_dep = k / len(predicted_states_dep)
  return (approximation_error_dep)


